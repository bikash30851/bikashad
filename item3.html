<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width = device-width, initial-scale = 1.0">
    <title>Bikash Portfolio Website</title>
    <!--This link normalizes the how content looks acroos different browsers-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/7.0.0/normalize.min.css">
    <!--This link is for all fonts.-->
    <script src="https://kit.fontawesome.com/fa5dd3366d.js" crossorigin="anonymous"></script>

    <!--Google Fonts-->
    <link href="https://fonts.googleapis.com/css2?family=Lora:400, 700|Roboto+Slab:400,700&display=swap" 
    rel="stylesheet">

    <!--Linking the local css file-->
    <link rel="stylesheet" href="css/itemstyle.css">

</head>

<body>
    <header>
        <div class="logo">
            <img src="img/image01.png" alt="">
        </div>
        <!--aria-label gives the button a name for accessibility reasons-->
        <button class="nav-toggle" aria-label="toggle navigation">
            <span class="hamburger"></span>
        </button>
        <nav class="nav">
            <ul class="nav__list">
                <li class="nav__item"><a href="index.html#home" class="nav__link">Home</a></li>
                <li class="nav__item"><a href="index.html#services" class="nav__link">My Services</a></li>
                <li class="nav__item"><a href="index.html#about" class="nav__link">About Me</a></li>
                <li class="nav__item"><a href="index.html#work" class="nav__link">My Work</a></li>
            </ul>
        </nav>
    </header>

    <!--Introduction-->
    <section class="intro">
        <h1 class="section__title section__title--intro">
            Reinforcement Learning <strong>Grid Environment</strong>
        </h1>
        <p class="section__subtitle section__subtitle--intro">Value Iteration using Python</p>
        <img src="img/ai.png" alt="Naca Live Image" class = "intro__img">
    </section>

    <div class="portfolio__item--individual">
        <p>When you try to get your hands on reinforcement learning, it is likely that Grid World Game is the very 
            first problem you meet with. It is the most basic as well as classic problem in reinforcement learning 
            and by implementing it on your own, I believe, is the best way to understand the basis of reinforcement 
            learning. Meanwhile, it is super fun to implement your own game and see how a robot manage to learn on 
            its own!
        </p>
        <img src="img/ai.png" alt="">
        <p>
            The rule is simple. Your agent/robot starts at the left-bottom corner(the ‘start’ sign) and
             ends at either +1 or -1 which is the corresponding reward. At each step, the agent has 4 possible
              actions including up, down, left and right, whereas the black block is a wall where your agent
               won’t be able to penetrate through. In order to make it more straight forward, our first 
               implementation assumes that each action is deterministic, that is, the agent will go where
                it intends to go. For instance, when the agent decides to take action up at (2, 0), it will
                 land in (1, 0) rather than (2, 1) or elsewhere. (We will add uncertainty in out second
                  implementation) However, it the agents hit the wall, it will remain at the same position.
        </p>
        <p>Agent
            This is the artificial intelligence part, as our agent should be able to learn from the process
             and thinks like a human. The key of the magic is value iteration.
            Value Iteration
            What our agent will finally learn is a policy, and a policy is a mapping from state to action, 
            simply instructs what the agent should do at each state. In our case, instead of learning a mapping 
            from state to action, we will leverage value iteration to firstly learn a mapping of state to
             value(which is the estimated reward) and based on the estimation, at each state, our agent will
              choose the best action that gives the highest estimated reward.
        </p>
    </div>



   

   <!--Footer-->
   <footer class="footer">
    <a href="mailto:bikash30851@gmail.com" class="footer__link">bikash30851@gmail.com</a>
    <ul class="ab">
        <li class="social-list__item"><a class="social-list__link" href="https://github.com/bikash30851"><i class="fa-brands fa-github-square"></i></a></li>
        <li class="social-list__item"><a class="social-list__link" href="https://www.linkedin.com/in/bikashad/"><i class="fa-brands fa-linkedin"></i></a></li>
        <li class="social-list__item"><a class="social-list__link" href="https://www.instagram.com/atombun_/"><i class="fa-brands fa-instagram"></i></a></li>
        <li class="social-list__item"><a class="social-list__link" href="https://twitter.com/AtomBun"><i class="fa-brands fa-twitter"></i></a></li>
    </ul>
    <copyright>Bikash Adhikari 
        <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="0.8em" width="0.8em" xmlns="http://www.w3.org/2000/svg">
            <path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm117.134 346.753c-1.592 1.867-39.776 45.731-109.851 45.731-84.692 0-144.484-63.26-144.484-145.567 0-81.303 62.004-143.401 143.762-143.401 66.957 0 101.965 37.315 103.422 38.904a12 12 0 0 1 1.238 14.623l-22.38 34.655c-4.049 6.267-12.774 7.351-18.234 2.295-.233-.214-26.529-23.88-61.88-23.88-46.116 0-73.916 33.575-73.916 76.082 0 39.602 25.514 79.692 74.277 79.692 38.697 0 65.28-28.338 65.544-28.625 5.132-5.565 14.059-5.033 18.508 1.053l24.547 33.572a12.001 12.001 0 0 1-.553 14.866z"></path>
        </svg>
        2021</copyright>
</footer>

<script src="js/index.js"></script>

</body>

</html>